{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"xresnet_heatmap.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"WC4yohXc-TdW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607646671208,"user_tz":180,"elapsed":5939,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"e9db26ae-01d8-473d-e727-58123bed5b3f"},"source":["!pip install -Uqq fastbook\n","!pip list -v | grep fastai"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 727kB 8.4MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 15.2MB/s \n","\u001b[K     |████████████████████████████████| 194kB 30.1MB/s \n","\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npnEzaVVhD4f"},"source":["from PIL import ImageFile\n","\n","import pandas as pd\n","import re\n","\n","from pathlib import Path\n","from datetime import datetime\n","\n","from fastbook import *\n","from fastai import * \n","from fastai.vision.widgets import *\n","from fastai.callback.fp16 import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z0bfqJacAZE0"},"source":["ImageFile.LOAD_TRUNCATED_IMAGES = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9JucHW2_x9n"},"source":["## Mount Drive"]},{"cell_type":"code","metadata":{"id":"hvEhj6cTjFlH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607646725843,"user_tz":180,"elapsed":17742,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"eed759a4-3994-4f8c-9968-14b69900653d"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FLgggSldAN9S"},"source":["## Raw data"]},{"cell_type":"code","metadata":{"id":"MgUI3LBVhkGu"},"source":["path = Path('/content/drive/MyDrive/MACHINLEARNING/DesafioAgTech2020/data/train_heatmap_ts')\n","test = Path('/content/drive/MyDrive/MACHINLEARNING/DesafioAgTech2020/data/test_heatmap_ts')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6iWKD13i3gb","executionInfo":{"status":"ok","timestamp":1607480552752,"user_tz":180,"elapsed":865,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"a905ba59-8ea5-4473-aabb-ca1a75628b3c"},"source":["path.exists()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"6X2wtmkR9fvm"},"source":["etiquetas_url = 'https://raw.githubusercontent.com/DesafiosAgTech/DesafioAgTech2020/master/dataset/Etiquetas.csv'\n","etiquetas =  pd.read_csv(etiquetas_url, error_bad_lines=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyPa_8wqAcO1"},"source":["## Parameters\r\n","\r\n","Parameters de arquitectura y de training"]},{"cell_type":"code","metadata":{"id":"t52gI-0hIEHo"},"source":["model_id = \"xresnet50_heatmap\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOISXergCzk-"},"source":["# instantiate balanced accuracy metric\n","balanced_accuracy = BalancedAccuracy()\n","\n","# dataloader\n","seed = 1 # seed split train-validation\n","valid_pct = 0.2 # % data validacion\n","bs = 32 # batch size\n","\n","# fine_tune model parameters\n","arch =  xresnet50  # architecture\n","loss_func = CrossEntropyLossFlat\n","pretrained = True\n","metrics = [balanced_accuracy, error_rate]\n","epochs = 22\n","lr = 10e-3\n","# opt_func = Adam (valor default)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rUG291lhBNYT"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"kkJisxxjhS1O"},"source":["# Load data with fastai\n","lotes2 = DataBlock(\n","    blocks=(ImageBlock, CategoryBlock), \n","    get_items=get_image_files, \n","    splitter=RandomSplitter(valid_pct=valid_pct, seed=seed),\n","    get_y=parent_label,\n","    item_tfms=RatioResize(224))\n","# square of resize pixels. Bigger the better but more hardware needed pg28 of fastai\n","\n","dls = lotes2.dataloaders(path, bs=bs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wINYIU1QEMkW"},"source":["Controles"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlMghQjHZu_4","executionInfo":{"status":"ok","timestamp":1607394383732,"user_tz":180,"elapsed":743,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"c56b8e71-0a6f-444e-fb85-84f2dff06b1b"},"source":["# N of training data\r\n","dls.train.n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["849"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-VNZqVjt8Vk","executionInfo":{"status":"ok","timestamp":1607635792292,"user_tz":180,"elapsed":775,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"8f7904f8-1118-4879-e557-a83404066964"},"source":["dls.train.vocab"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A', 'B', 'G', 'M', 'N', 'P', 'R', 'S', 'T', 'U', 'X', 'aa', 'm', 's']"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"BFoBcFViED79"},"source":["train_lbls = L(map(lambda x: classes[x[1]], dls.train_ds))\r\n","label_counter = Counter(train_lbls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBdVbLkKvsNo","executionInfo":{"status":"ok","timestamp":1607454348224,"user_tz":180,"elapsed":996,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"5dbfcc91-9207-4719-9f98-b14bd398065c"},"source":["label_counter"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'A': 1,\n","         'B': 5,\n","         'G': 1,\n","         'M': 174,\n","         'N': 63,\n","         'P': 47,\n","         'R': 4,\n","         'S': 263,\n","         'T': 2,\n","         'U': 9,\n","         'X': 29,\n","         'aa': 1,\n","         'm': 4,\n","         's': 77})"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"Vu9S9DHDjekI"},"source":["dls.valid.show_batch(max_n=1, nrows=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6ZzeY-U_bid"},"source":["dls.show_batch()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JV_dytAtDrBs"},"source":["## Sample weights"]},{"cell_type":"code","metadata":{"id":"uWKkicUOgWTH"},"source":["def make_weights_for_balanced_classes(labels, nclasses):\n","  \"\"\"\n","  Returns weight of each image \n","  Weights are inversely correlated to class frequency \n","  \"\"\"\n","  count = [0] * nclasses                                                      \n","  for l in labels:                                                         \n","      count[l] += 1                                                     \n","  weight_per_class = [0.] * nclasses                                      \n","  N = float(sum(count))                                                   \n","  for i in range(nclasses):                                                   \n","      weight_per_class[i] = N/float(count[i])                                 \n","  weight = [0] * len(labels)                                              \n","  for idx, val in enumerate(labels):                                          \n","      weight[idx] = weight_per_class[val]                                  \n","  return weight\n","\n","\n","def get_sampler(dataloader):\n","  \"\"\"\n","  Returns sampler using weights for a given data\n","  Esta funcion es una alternativa a get_weights()\n","  \"\"\"\n","  imagenes = list()\n","  labels = list()\n","  for i,l in dataloader.train:\n","    imagenes.append(i)\n","    labels.append(l)\n","  imagenes2 = torch.cat(imagenes)\n","  labels2 = torch.cat(labels)\n","  n_classes = len(torch.unique(labels2))\n","  weights = make_weights_for_balanced_classes(labels2, n_classes)                                                                \n","  weights = torch.DoubleTensor(weights)                                       \n","  sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n","  return sampler\n","\n","\n","def get_weights(dls):\n","  \"\"\"\n","  Get weights based on the class distribution in the training data\n","  Basado en https://forums.fast.ai/t/oversampling-in-fastai2/73721/3\n","  Esta funcion es una alternativa a get_sampler()\n","  \"\"\"\n","  # 0th index would provide the vocab from text\n","  # 1st index would provide the vocab from classes\n","  classes = dls.train.vocab\n","  #Get label ids from the dataset using map\n","  #train_lb_ids = L(map(lambda x: x[1], dls.train_ds))\n","  # Get the actual labels from the label_ids & the vocab\n","  #train_lbls = L(map(lambda x: classes[x], train_lb_ids))\n","  #Combine the above into a single\n","  train_lbls = L(map(lambda x: classes[x[1]], dls.train_ds))\n","  label_counter = Counter(train_lbls)\n","  n_most_common_class = max(label_counter.values()); \n","  print(f'Occurrences of the most common class {n_most_common_class}')\n","  # Source: https://discuss.pytorch.org/t/what-is-the-weight-values-mean-in-torch-nn-crossentropyloss/11455/9\n","  # weights = [n_most_common_class/v for k, v in label_counter.items() if v > 0]; return weights \n","  weights = [n_most_common_class/label_counter[k] for  k in dls.train.vocab ]\n","  return weights\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8nVssj4EIyJ"},"source":["# create dataloader using sampler\r\n","dls2 =  lotes2.dataloaders(path, bs=bs, sampler=get_sampler(dls))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pr-Ie-tPKBjr"},"source":["## Learning rate\r\n","\r\n","Find \"optimal\" learning rate"]},{"cell_type":"code","metadata":{"id":"Y_9My15zyPGD"},"source":["learn = None\n","learn = cnn_learner(\n","    dls2, arch, loss_func=loss_func(), pretrained=pretrained\n","    , metrics=metrics)\n","lr_min, lr_steep = learn.lr_find()\n","# # # 10e-3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ox4QiXRaKuAg"},"source":["## Train - validate"]},{"cell_type":"code","metadata":{"id":"KVBvEaxGkW9f"},"source":["# def set_seeds():\n","#   random.seed(42)\n","#   np.random.seed(12345)\n","#   torch.manual_seed(1234)\n","#   torch.backends.cudnn.deterministic = True\n","#   torch.backends.cudnn.benchmark = False\n","\n","# set_seeds()\n","\n","learn = None\n","learn = cnn_learner(\n","    dls2, arch, loss_func=loss_func(), pretrained=pretrained, metrics= metrics).to_fp16()\n","learn.fine_tune(epochs=epochs, base_lr=lr)\n","learn.recorder.plot_loss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VYjzSPiLmXs"},"source":["### Performance\r\n","\r\n","Validation metrics"]},{"cell_type":"code","metadata":{"id":"XKBbFA6hmrnh"},"source":["interp = ClassificationInterpretation.from_learner(learn)\n","interp.plot_confusion_matrix()\n","interp.most_confused(min_val=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R25eYbHroTOG"},"source":["interp.plot_top_losses(5, nrows=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6piHiOjkJajs"},"source":["# # loss of each validation image\r\n","# interp.losses.abs()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7pPw0ZBtMJr4"},"source":["## Train\r\n","\r\n","Final training with all data (train + validation)"]},{"cell_type":"code","metadata":{"id":"MNYi_ubpDkp1"},"source":["lotes_alldata = DataBlock(\n","    blocks=(ImageBlock, CategoryBlock), \n","    get_items=get_image_files, \n","    splitter=RandomSplitter(valid_pct=0.0, seed=seed),\n","    get_y=parent_label,\n","    item_tfms=RatioResize(224))\n","\n","dls_alldata = lotes_alldata.dataloaders(path, bs=bs)\n","dls_alldata2 = lotes_alldata.dataloaders(\n","    path, bs=bs, sampler=get_sampler(dls_alldata))\n","\n","learn = None\n","learn = cnn_learner(\n","    dls_alldata2, arch, loss_func=loss_func(), pretrained=pretrained, metrics=metrics).to_fp16()\n","learn.fine_tune(epochs=epochs, base_lr=lr)\n","learn.recorder.plot_loss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52smwUifGS1_"},"source":["## Save"]},{"cell_type":"code","metadata":{"id":"nk0YsbI7kzlr"},"source":["model_file = f'/content/drive/MyDrive/MACHINLEARNING/DesafioAgTech2020/{model_id}.pkl'\r\n","\r\n","# save models as pkl\r\n","learn.export(model_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uiwIGvuWGwuY"},"source":["def generate_submit_from_learner(\r\n","    pkt_path_str\r\n","    ,test_path_str='/content/drive/MyDrive/MACHINLEARNING/DesafioAgTech2020/data/test'\r\n","    ,export_path_str = '/content/drive/MyDrive/MACHINLEARNING/DesafioAgTech2020/submit/'):\r\n","    \"\"\"\r\n","    Submits csv ready to upload in the export path. Date at the end\r\n","    Input: \r\n","      - pkl learner path as string\r\n","      - path of test directory (.png) as string. Must end in GlobalId.png\r\n","      - path to export directory as string\r\n","    \"\"\"\r\n","    etiquetas_url = 'https://raw.githubusercontent.com/DesafiosAgTech/DesafioAgTech2020/master/dataset/Etiquetas.csv'\r\n","    etiquetas =  pd.read_csv(etiquetas_url, error_bad_lines=False)\r\n","    # Load model and predict using same transformation?\r\n","    learn = load_learner(str(pkt_path_str))\r\n","    test_dl = learn.dls.test_dl(get_image_files(test_path_str))\r\n","    # Predicts and returns most probable class\r\n","    preds,y = learn.get_preds(dl = test_dl)\r\n","    y = torch.argmax(preds, dim = 1)\r\n","    # Predicted to corresponding CultivoId + add global id for submit\r\n","    glob_list = [re.findall(r'(\\d+).png', r) for r in [str(p) for p in test_dl.items]]\r\n","    globalids = [int(id) for sub in glob_list for id in sub] \r\n","    prediction = [learn.dls.vocab[p] for p in y.tolist()]\r\n","    prediction_df = pd.DataFrame(zip(globalids,prediction), columns=['globalid','clase'])\r\n","    submit = prediction_df.merge(\r\n","        etiquetas, how = \"left\", left_on= 'clase', right_on='Cultivo')[['globalid','CultivoId']]\r\n","    # exports submit\r\n","    now = datetime.now()\r\n","    file_name = \\\r\n","      str(export_path_str) + now.strftime('%Y%m%d%H%M') + str(test_path_str).split(\"/\")[-1] + '.csv'\r\n","    submit.to_csv(file_name, header=False, index=False)\r\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16nVR25ES1mL","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1607653386536,"user_tz":180,"elapsed":100677,"user":{"displayName":"Franco Betteo","photoUrl":"","userId":"14302285977517936642"}},"outputId":"7ba7c138-3774-434c-a481-3055a74e0651"},"source":["# submit csv of results\n","generate_submit_from_learner(model_file, test_path_str=str(test))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]}]}